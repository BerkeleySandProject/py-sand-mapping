{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b904b9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/suraj.nair/.conda/envs/didl-covid/lib/python3.7/site-packages/google/auth/__init__.py:55: Python37DeprecationWarning: After January 1, 2024, new releases of this library will drop support for Python 3.7. More details about Python 3.7 support can be found at https://cloud.google.com/python/docs/python37-sunset/\n",
      "  warnings.warn(message, Python37DeprecationWarning)\n",
      "/home/suraj.nair/.conda/envs/didl-covid/lib/python3.7/site-packages/google/oauth2/__init__.py:40: Python37DeprecationWarning: After January 1, 2024, new releases of this library will drop support for Python 3.7. More details about Python 3.7 support can be found at https://cloud.google.com/python/docs/python37-sunset/\n",
      "  warnings.warn(message, Python37DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from geemap import ml\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import geemap, ee\n",
    "import geopandas as gpd\n",
    "\n",
    "from geopandas.geoseries import *\n",
    "from shapely.geometry import *\n",
    "\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from matplotlib.pyplot import Line2D\n",
    "import gc\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77428ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "        ee.Initialize()\n",
    "except Exception as e:\n",
    "        ee.Authenticate()\n",
    "        ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e869fb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mappy(x):\n",
    "    return ee.String(x).replace('#', '\\n', 'g')\n",
    "\n",
    "\n",
    "def decode_qamask(img: ee.Image) -> ee.Image:\n",
    "    '''\n",
    "    Args\n",
    "    - img: ee.Image, Sentinel 2 image containing 'pixel_qa' band\n",
    "    Returns\n",
    "    - masks: ee.Image, \n",
    "    Pixel QA Bit Flags\n",
    "    Bit  Attribute\n",
    "    0    Fill\n",
    "    10   Cloud\n",
    "    11   Cirrus\n",
    "    '''\n",
    "    qa = img.select('QA60')\n",
    "    cloud = qa.bitwiseAnd(1024).eq(0)  # 0 = cloud, 1 = not cloud\n",
    "    cloud = cloud.updateMask(cloud).rename(['pxqa_cloud'])\n",
    "    \n",
    "    cirrus = qa.bitwiseAnd(2048).eq(0)  # 0 = cloud, 1 = not cloud\n",
    "    cirrus = cirrus.updateMask(cirrus).rename(['pxqa_cirrus'])\n",
    "    masks = ee.Image.cat([cloud, cirrus])\n",
    "    return masks\n",
    "\n",
    "\n",
    "def mask_qaclear(img: ee.Image) -> ee.Image:\n",
    "    '''\n",
    "    Args\n",
    "    - img: ee.Image\n",
    "    Returns\n",
    "    - img: ee.Image, input image with cloud, cirrus\n",
    "        pixels masked out\n",
    "    '''\n",
    "    qam = decode_qamask(img)\n",
    "    cloud_mask = qam.select('pxqa_cloud')\n",
    "    cirrus_mask = qam.select('pxqa_cirrus')\n",
    "    return img.updateMask(cloud_mask).updateMask(cirrus_mask).divide(10000)\n",
    "\n",
    "def getS1_collection(START_DATE, END_DATE):\n",
    "    #Import Sentinel 1 and filter data series:\n",
    "    s1Collection =  ee.ImageCollection('COPERNICUS/S1_GRD')\\\n",
    "    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\\\n",
    "    .filter(ee.Filter.eq('instrumentMode', 'IW'))\\\n",
    "    .filterDate(START_DATE, END_DATE)\n",
    "    \n",
    "    return s1Collection\n",
    "\n",
    "def getS2_collection(START_DATE, END_DATE, cloud_pct = 10):\n",
    "\n",
    "    s2Collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\\\n",
    "                      .filterDate(START_DATE, END_DATE)\\\n",
    "                      .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE',cloud_pct))\\\n",
    "                      .map(mask_qaclear)\n",
    "    \n",
    "    return s2Collection\n",
    "\n",
    "def addBands(expr, band_map, name):\n",
    "    expr_s2 = ee.Image().expression({\n",
    "        'expression': expr,\n",
    "      'map': band_map}).rename(name)\n",
    "    \n",
    "    return expr_s2\n",
    "\n",
    "def s1s2_image(START_DATE, END_DATE):\n",
    "\n",
    "    s1Collection = getS1_collection(START_DATE, END_DATE)\n",
    "    s2Collection = getS2_collection(START_DATE, END_DATE)\n",
    "    #Calculate median image of time period\n",
    "    s1_image = ee.Image(s1Collection.median()) \n",
    "    s2 = s2Collection.median()\n",
    "    \n",
    "        #### Add S2 Bands\n",
    "    mTGSI_expr = '(R - B + SWIR2 - NIR) / (R + G + B + SWIR2 + NIR)'  \n",
    "    mTGSI = s2.expression(mTGSI_expr, \n",
    "                          {\n",
    "                            'R': s2.select('B4'),\n",
    "                            'G': s2.select('B3'),\n",
    "                            'B': s2.select('B2'),\n",
    "                            'NIR': s2.select('B8'),\n",
    "                            'SWIR2': s2.select('B12'),\n",
    "                            'SWIR1': s2.select('B11')\n",
    "                          }).rename('mTGSI')\n",
    "\n",
    "    BSI_expr = '((RED + SWIR1) - (NIR + BLUE)) / ((RED + SWIR1) + (NIR + BLUE))'\n",
    "    BSI = s2.expression(BSI_expr, \n",
    "                          {\n",
    "                            'NIR' : s2.select('B8'),\n",
    "                            'RED' : s2.select('B4'),\n",
    "                            'SWIR1': s2.select('B11'),\n",
    "                            'BLUE': s2.select('B2')\n",
    "                          }).rename('BSI')\n",
    "    \n",
    "    \n",
    "    NDWI_expr = '(GREEN - NIR) / (GREEN + NIR)'\n",
    "    NDWI = s2.expression(NDWI_expr, \n",
    "                          {\n",
    "                         'NIR' : s2.select('B8'),\n",
    "                        'GREEN' : s2.select('B3')\n",
    "                          }).rename('NDWI')\n",
    "\n",
    "    ### Add Dynamic World\n",
    "    colFilter = ee.Filter.And(ee.Filter.bounds(ee.Geometry.Point(84.37454, 25.05473)), ee.Filter.date(START_DATE, END_DATE))\n",
    "\n",
    "    DW = ee.ImageCollection('GOOGLE/DYNAMICWORLD/V1').filter(colFilter).median()\n",
    "\n",
    "    nameOfBands = DW.bandNames().remove('label')\n",
    "    # ['water', 'trees', 'grass', 'flooded_vegetation', 'crops', 'shrub_and_scrub', 'built', 'bare', 'snow_and_ice']\n",
    "    DW = DW.select(nameOfBands)\n",
    "\n",
    "\n",
    "    #### All bands together\n",
    "    sentinelComp = s2.addBands(s1_image.select([s1_band, s1_band2])).addBands(mTGSI).addBands(BSI).addBands(NDWI)\n",
    "\n",
    "    outBands =  [\"B2\",\"B3\",\"B4\",\"B8\",\"B8A\",\"B11\",\"B12\",\"VV\",\"VH\",\"mTGSI\",\"BSI\",\"NDWI\"]\n",
    "\n",
    "    finalComp= sentinelComp.select(outBands).addBands(DW)\n",
    "    \n",
    "    return finalComp\n",
    "\n",
    "\n",
    "def get_sgr_feat(ee_img, distid):\n",
    "    \n",
    "    df_dist1 = gpd.read_file(f\"/data/sand_mining/rivers/districts/india-rivers_multipolygons_{distid}.geojson\")\n",
    "    temp1 = geemap.geopandas_to_ee(df_dist1)\n",
    "\n",
    "    sand_mask = ee_img.eq(1)\n",
    "    gravel_mask = ee_img.eq(2)\n",
    "\n",
    "    reduced = sand_mask.reduceRegion(\n",
    "                  reducer=ee.Reducer.sum(),\n",
    "                  geometry=temp1,\n",
    "                  scale=10, \n",
    "                  tileScale = 3\n",
    "                   )\n",
    "\n",
    "    sand_reduced = ee.Feature(None, reduced)\n",
    "    sand_reduced = sand_reduced.set('distid', distid)\n",
    "    sand_reduced = sand_reduced.set('class', 'sand')\n",
    "\n",
    "    reduced = gravel_mask.reduceRegion(\n",
    "                  reducer=ee.Reducer.sum(),\n",
    "                  geometry=temp1,\n",
    "                  scale=10, \n",
    "                  tileScale = 3\n",
    "                   )\n",
    "\n",
    "    gravel_reduced = ee.Feature(None, reduced)\n",
    "    gravel_reduced = gravel_reduced.set('distid', distid)\n",
    "    gravel_reduced = gravel_reduced.set('class', 'gravel')\n",
    "\n",
    "    sgr = ee.FeatureCollection([sand_reduced, gravel_reduced])\n",
    "    \n",
    "    return sgr\n",
    "\n",
    "\n",
    "def get_final_classification(image, model):\n",
    "    #### SNIC\n",
    "    size_segmentation = 10\n",
    "\n",
    "    #Segmentation using a SNIC approach based on the dataset previosly generated\n",
    "    seeds = ee.Algorithms.Image.Segmentation.seedGrid(size_segmentation)\n",
    "    snic = ee.Algorithms.Image.Segmentation.SNIC(**{\n",
    "      'image': image, #our multi-band image with selected bands same as for pixel-based\n",
    "      'compactness': 0.8,  #allow flexibility in object shape, no need to force compactness\n",
    "      'connectivity': 8, #use all 8 neighboring pixels in a pixel neighborhood\n",
    "      'neighborhoodSize': 256, \n",
    "      'seeds': seeds\n",
    "    })\n",
    "\n",
    "    ####Classification\n",
    "    predictionBands=snic.bandNames().remove(\"clusters\") \n",
    "    renamed_bands = ['B2_median', 'B3_median', 'B4_median', 'B8_median', 'B8A_median', 'B11_median', 'B12_median', \n",
    "    'VV_median', 'VH_median', 'mTGSI_median', 'BSI_median', 'NDWI_median', 'water_median', 'trees_median', 'grass_median', \n",
    "    'flooded_vegetation_median', 'crops_median', 'shrub_and_scrub_median', 'built_median', 'bare_median', 'snow_and_ice_median']\n",
    "\n",
    "    snic = snic.select(predictionBands, renamed_bands)\n",
    "\n",
    "    classification = snic.classify(model)\n",
    "    \n",
    "    return classification\n",
    "\n",
    "\n",
    "def calculateMean(image):\n",
    "    mean = image.reduceRegion(**{\n",
    "    'reducer': ee.Reducer.mean(),\n",
    "    'geometry': CURRENT_GEOMETRY,\n",
    "    'scale': 10,  #Adjust the scale according to your needs\n",
    "    'maxPixels': 1e13, \n",
    "    'tileScale':3\n",
    "      })\n",
    "    return image.set('mean_value', mean.get('classification'))  #Replace with the actual band name\n",
    "\n",
    "\n",
    "def get_class_coll(START_YEAR, END_YEAR, clip_geom, class_val = 1):\n",
    "    print(\"Started Coll\", datetime.now())\n",
    "    imgs = ee.List([])\n",
    "    dates = []\n",
    "    for start, end in list(zip(pd.date_range(f'{START_YEAR}-01-01', f'{END_YEAR}-12-31', freq= 'MS' ), \n",
    "        pd.date_range(f'{START_YEAR}-01-01', f'{END_YEAR}-12-31', freq= 'M' ))):\n",
    "        img = s1s2_image(str(start.date()), str(end.date()))\n",
    "        hasNoBands = img.bandNames()\n",
    "        a = hasNoBands.length()\n",
    "        a = a.getInfo()\n",
    "        if a == 21:\n",
    "            img = img.clip(clip_geom)\n",
    "            img_class = get_final_classification(img, RF)\n",
    "            mask = img_class.eq(class_val)\n",
    "            mask = mask.set('ym', start.strftime(\"%Y-%m\"))\n",
    "            imgs = imgs.add(ee.Image(mask))\n",
    "            dates.append(start.strftime(\"%Y-%m\"))\n",
    "            \n",
    "    img_coll = ee.ImageCollection.fromImages(imgs)\n",
    "#     print(dates)\n",
    "    print(\"Completed\", datetime.now())\n",
    "    \n",
    "    return img_coll\n",
    "\n",
    "\n",
    "def convert_img_coll_to_df(imageCollection):\n",
    "    # # Extract mean values as a list\n",
    "    mean_list = imageCollection.aggregate_array('mean_value').getInfo()\n",
    "\n",
    "    # Convert the list to a Pandas DataFrame\n",
    "    df = pd.DataFrame({'mean_value': mean_list})\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_buffer(poly, buffer_m = 1000, tolerance_m = 250):\n",
    "    seg = poly.to_crs(poly.estimate_utm_crs())\n",
    "    minx, miny, maxx, maxy = seg.bounds.values[0]\n",
    "    bbox = gpd.GeoDataFrame(geometry = [Polygon([(minx, maxy), \n",
    "                                              (maxx, maxy), \n",
    "                                              (maxx, miny), \n",
    "                                              (minx, miny)])])\n",
    "    \n",
    "    buffered_poly = seg.simplify(tolerance_m).buffer(buffer_m)\n",
    "    buffered_poly = buffered_poly.clip(bbox)\n",
    "    buffered_poly = buffered_poly.to_crs(poly.crs).reset_index()\n",
    "    buffered_poly = buffered_poly.rename(columns = {0:'geometry'})\n",
    "    return buffered_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acf175a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Models\n",
    "\n",
    "fc = ee.FeatureCollection(\"projects/gee-sand/assets/RF_sklearn_seg10_n1214_d50_msl1_mss2_mf-None_bTrue\")\n",
    "tree_strings = fc.aggregate_array('tree').map(mappy)\n",
    "RF = ee.Classifier.decisionTreeEnsemble(tree_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe5ee76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Define Globals\n",
    "\n",
    "s1_band = 'VV'\n",
    "s1_band2 = 'VH'\n",
    "s1_band3 = 'angle'\n",
    "\n",
    "\n",
    "#### Note on river and district shapefiles\n",
    "# India district boundaries: /data/sand_mining/shapefiles\n",
    "# River polygons clipped to district boundaries: /data/sand_mining/rivers/districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa69f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = gpd.read_file(\"/data/sand_mining/rivers/segments_merged.geojson\")\n",
    "segments['pair_id'] = segments.apply(lambda x: f\"{x['osm_id']}-{x['seg_id']}\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "764f893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_ids = segments['pair_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1dd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1993017-7920\n",
      "Started Coll 2023-12-16 20:30:40.419851\n",
      "Completed 2023-12-16 20:31:06.232527\n",
      "Started Coll 2023-12-16 20:31:06.232748\n",
      "Completed 2023-12-16 20:31:30.837514\n",
      "3031475-7920\n",
      "Started Coll 2023-12-16 20:31:33.845574\n",
      "Completed 2023-12-16 20:31:58.558055\n",
      "Started Coll 2023-12-16 20:31:58.558145\n",
      "Completed 2023-12-16 20:32:23.206345\n",
      "9050989-7920\n",
      "Started Coll 2023-12-16 20:32:26.323277\n",
      "Completed 2023-12-16 20:32:50.485382\n",
      "Started Coll 2023-12-16 20:32:50.485495\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for pair in pair_ids[1:]:\n",
    "    print(pair)\n",
    "    seg = segments[segments['pair_id'] == pair]\n",
    "    buffer_seg = get_buffer(seg)\n",
    "    \n",
    "    #Create Feature Collection\n",
    "    ee_fc = geemap.geopandas_to_ee(buffer_seg)\n",
    "    CURRENT_GEOMETRY = ee_fc\n",
    "\n",
    "    #Get sand and gravel\n",
    "    img_coll_sand = get_class_coll(2018, 2022, CURRENT_GEOMETRY)\n",
    "    img_coll_gravel = get_class_coll(2018, 2022, CURRENT_GEOMETRY, class_val = 2)\n",
    "\n",
    "    #Get Means over the Image Collection\n",
    "    img_coll_fc_sand = img_coll_sand.map(calculateMean)\n",
    "    img_coll_fc_gravel = img_coll_gravel.map(calculateMean)\n",
    "\n",
    "\n",
    "    task1 = ee.batch.Export.table.toDrive(\n",
    "              collection= ee.FeatureCollection(img_coll_fc_sand),\n",
    "              description= f'{pair}_sand',\n",
    "              fileFormat='CSV', \n",
    "              folder = 'sgr_sand',\n",
    "            selectors = ['mean_value', 'ym'])\n",
    "\n",
    "    task2 = ee.batch.Export.table.toDrive(\n",
    "              collection= ee.FeatureCollection(img_coll_fc_gravel),\n",
    "              description= f'{pair}_gravel',\n",
    "              fileFormat='CSV', \n",
    "              folder = 'sgr_gravel',\n",
    "            selectors = ['mean_value', 'ym']\n",
    "            )\n",
    "\n",
    "    task1.start()\n",
    "    task2.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39d033e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7e66d54d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2162b2d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Sand Coll 2023-12-16 20:10:22.479364\n",
      "Completed 2023-12-16 20:10:48.578896\n",
      "Started Sand Coll 2023-12-16 20:10:48.579236\n",
      "Completed 2023-12-16 20:11:14.906866\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39531f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_img_coll_to_df(img_coll_fc_sand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0e6479bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1 = img_coll.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5514f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ee' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0c2876394226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mee\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ee' is not defined"
     ]
    }
   ],
   "source": [
    "ee"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "didl-covid",
   "language": "python",
   "name": "didl-covid"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
